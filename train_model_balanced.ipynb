{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.thickness_dataset import ThicknessDataset, ToTensor\n",
    "from src.models import U_Net\n",
    "from src.resnet import ResNet\n",
    "from src.trainer import Trainer\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "PATH = \"data\\gen_data_6000_v2\"\n",
    "\n",
    "\n",
    "augs = A.Compose([A.Normalize(mean = (0, 0, 0),\n",
    "                              std  = (1, 1, 1)),\n",
    "                 ToTensorV2()])\n",
    "thickness_dataset = ThicknessDataset(PATH,  transform=augs)\n",
    "\n",
    "# https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/03/08/image-mean-std.html Could be worth attempting to normalise the data\n",
    "# https://stackoverflow.com/questions/41428868/image-preprocessing-in-deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 \n",
    "sample = thickness_dataset[idx]\n",
    "\n",
    "print(\"cam_pos: \", sample['cam_pos'])\n",
    "print(\"catagory: \", sample['catagory'])\n",
    "print(\"model_id: \", sample['model_id'])\n",
    "print(\"sample_no: \", sample['sample_no'])\n",
    "\n",
    "img = sample['img']\n",
    "vis = sample['depth_map'].reshape(128,128)\n",
    "# vis = vis[np.nonzero(vis)]\n",
    "\n",
    "# print(img.shape)\n",
    "# img = img.numpy().transpose(1, 2, 0)\n",
    "\n",
    "# # Displays ehhe\n",
    "# fig = plt.figure(figsize=(8,6))\n",
    "# ax = fig.add_subplot()\n",
    "# ax.imshow(vis)\n",
    "\n",
    "# plt.title(f\"{sample['catagory']}, {sample['model_id']}, {sample['sample_no']}\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and std\n",
    "image_loader = DataLoader(thickness_dataset, \n",
    "                          batch_size  = 128, \n",
    "                          shuffle     = False, \n",
    "                          num_workers = 4,\n",
    "                          pin_memory  = True)\n",
    "\n",
    "# placeholders\n",
    "psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "# loop through images\n",
    "for inputs in tqdm(image_loader):\n",
    "    psum    += inputs['img'].sum(axis        = [0, 2, 3])\n",
    "    psum_sq += (inputs['img'] ** 2).sum(axis = [0, 2, 3])\n",
    "\n",
    "# pixel count\n",
    "count = len(thickness_dataset) * 128 * 128\n",
    "\n",
    "# mean and std\n",
    "total_mean = psum / count\n",
    "total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "total_std  = torch.sqrt(total_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = A.Compose([A.Normalize(mean = total_mean,\n",
    "                              std  = total_std),\n",
    "                 ToTensorV2()])\n",
    "thickness_dataset = ThicknessDataset(PATH, transform=augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 \n",
    "sample = thickness_dataset[idx]\n",
    "\n",
    "print(\"cam_pos: \", sample['cam_pos'])\n",
    "print(\"catagory: \", sample['catagory'])\n",
    "print(\"model_id: \", sample['model_id'])\n",
    "print(\"sample_no: \", sample['sample_no'])\n",
    "\n",
    "img = sample['img']\n",
    "print(img.shape)\n",
    "img = img.numpy().transpose(1, 2, 0)\n",
    "\n",
    "# Displays ehhe\n",
    "# fig = plt.figure(figsize=(8,6))\n",
    "# ax = fig.add_subplot()\n",
    "# ax.imshow(img)\n",
    "# plt.title(f\"{sample['catagory']}, {sample['model_id']}, {sample['sample_no']}\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mandatory_test_models = [\"88d183f319cddb7344221bef0fa3c36b\",\"ce40b134b11e8c822bbc2c380e91dfe2\",\"67bc9bec05f78850f9e08161aea27d2f\",\"ba494b33be3a3e0dc1bbb501b1d87871\",\"15cc3d9020384e8d6e09a8e31c7575c5\",\"bc6a3fa659dd7ec0c62ac18334863d36\",\"46dbba829a57ace8cffd61677456447e\",\"1d527bbed4d12817fa3bb91f4e3cd35f\",\"f400eb5421283e8a102f4912aece242b\",\"899af991203577f019790c8746d79a6f\"]\n",
    "\n",
    "\n",
    "# find the root indexs of the test model in the thickness_dataset . dataframe\n",
    "test_idx = []\n",
    "for i in range(len(mandatory_test_models)):\n",
    "    test_idx.append(thickness_dataset.dataframe[thickness_dataset.dataframe[\"model_id\"] == mandatory_test_models[i]].index[0])\n",
    "\n",
    "np.array(test_idx, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thickness_dataset[1485]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "def customRandomSplit(dataset, train_size, val_size, test_size):\n",
    "    # TODO: DONT think its adding in the indices +1 and +2 need to add that to all the indices arrays\n",
    "    rnd_Seed=42\n",
    "    mandatory_test_models = [\"88d183f319cddb7344221bef0fa3c36b\",\"ce40b134b11e8c822bbc2c380e91dfe2\",\"67bc9bec05f78850f9e08161aea27d2f\",\"ba494b33be3a3e0dc1bbb501b1d87871\",\"15cc3d9020384e8d6e09a8e31c7575c5\",\"bc6a3fa659dd7ec0c62ac18334863d36\",\"46dbba829a57ace8cffd61677456447e\",\"1d527bbed4d12817fa3bb91f4e3cd35f\",\"f400eb5421283e8a102f4912aece242b\",\"899af991203577f019790c8746d79a6f\"]\n",
    "    data_len = len(dataset)\n",
    "    train_size = int(round((train_size * data_len)/3))\n",
    "    val_size   = int(round((val_size * data_len)/3))\n",
    "    test_size  = int(round((test_size * data_len)/3))\n",
    "\n",
    "    assert train_size*3 + val_size*3 + test_size*3 == data_len, \"The split sizes do not add up to the dataset size\"\n",
    "    # Using pytorch subsets to split the dataset\n",
    "    # 3 is the number of frames per model\n",
    "    # randomly sample indices for the train size\n",
    "    choices = np.arange(0, data_len, 3, dtype=int)\n",
    "    # get the index numbers for the mandatory test models from dataset dataframe\n",
    "    mandatory_test_indices = []\n",
    "    for i in range(len(mandatory_test_models)):\n",
    "        mandatory_test_indices.append(thickness_dataset.dataframe[thickness_dataset.dataframe[\"model_id\"] == mandatory_test_models[i]].index[0])\n",
    "    mandatory_test_indices = np.array(np.array(mandatory_test_indices), dtype=int)\n",
    "    # remove the values in mandatory_test_indices from the choices\n",
    "    choices = np.setdiff1d(choices, mandatory_test_indices)\n",
    "    \n",
    "    np.random.seed(rnd_Seed)\n",
    "    np.random.shuffle(choices)\n",
    "    # randomly sample indices for the train size\n",
    "    train_indices = choices[:train_size]\n",
    "    # randomly sample indices for the val size\n",
    "    val_indices = choices[train_size:train_size+val_size]\n",
    "    # randomly sample indices for the test size\n",
    "    test_indices = choices[train_size+val_size:train_size+val_size+test_size]\n",
    "    # add the mandatory test indices to the test indices\n",
    "    test_indices = np.concatenate((test_indices, mandatory_test_indices))\n",
    "    # final check the values in mandatory_test_indices are in test_indices\n",
    "    assert np.all(np.isin(mandatory_test_indices, test_indices)), \"The mandatory test indices are not in the test indices\"\n",
    "    # check mandatory_test_indices values arent in the other 2\n",
    "    assert np.all(np.isin(mandatory_test_indices, train_indices)) == False, \"The mandatory test indices are in the train indices\"\n",
    "    assert np.all(np.isin(mandatory_test_indices, val_indices)) == False, \"The mandatory test indices are in the val indices\"\n",
    "\n",
    "\n",
    "    train_indices = np.concatenate((train_indices, train_indices+1, train_indices+2))\n",
    "    val_indices = np.concatenate((val_indices, val_indices+1, val_indices+2))\n",
    "    test_indices = np.concatenate((test_indices, test_indices+1, test_indices+2))\n",
    "    # no intersections between the sets\n",
    "    it = np.intersect1d(train_indices, val_indices)\n",
    "    it2 = np.intersect1d(train_indices, test_indices)\n",
    "    it3 = np.intersect1d(val_indices, test_indices)\n",
    "    assert len(it) == 0 , f\"The train and val sets have the same indices {it}\"\n",
    "    assert len(it2) == 0 , f\"The train and test sets have the same indices {it2}\"\n",
    "    assert len(it3) == 0 , f\"The val and test sets have the same indices{it3}\"\n",
    "    \n",
    "    # create the subsets\n",
    "    train_set = Subset(dataset, train_indices)\n",
    "    val_set   = Subset(dataset, val_indices,)\n",
    "    test_set  = Subset(dataset, test_indices)\n",
    "    assert len(train_set) + len(val_set) + len(test_set) == data_len, \"The split sizes do not add up to the dataset size\"\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.7\n",
    "valid_split = 0.1\n",
    "test_split = 0.2\n",
    "train_dataset, valid_dataset, test_dataset = customRandomSplit(thickness_dataset, train_split, valid_split, test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 # 16\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNet()\n",
    "\n",
    "model = U_Net()\n",
    "\n",
    "epochs = 200\n",
    "learning_rate = 2e-4\n",
    "scheduler = None\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, verbose=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0005)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "trainer = Trainer(model, optimizer, loss_fn, train_dataloader, valid_dataloader, scheduler=scheduler)\n",
    "trained_model = trainer.run(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "trained_model=model\n",
    "trained_model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = iter(train_dataloader).next()\n",
    "    image, label = data['img'].to(device, dtype=torch.float), data['thick_map'].to(device, dtype=torch.float)\n",
    "    output = trained_model(image)\n",
    "    image = image.cpu().numpy().transpose(0,2,3,1)\n",
    "    label = label.cpu().numpy()\n",
    "    output = output.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(image[0], cmap='gray')\n",
    "    plt.title('Input Image')\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(label[0].reshape(128,128), cmap='gray')\n",
    "    plt.title('Ground Truth')\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(output[0].reshape(128,128), cmap='gray')\n",
    "    plt.title('Predicted Thickness Map')\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(abs(label[0]-output[0]).reshape(128,128), cmap='gray')\n",
    "    plt.title('Diff')\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "270a635b83e65d335eba5d097089b0ff08369f0634f543893019998ee28e2990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
