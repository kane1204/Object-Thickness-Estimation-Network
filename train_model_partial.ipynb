{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file trains on with a subset missing and we will evaluate the performance of the model on the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.thickness_dataset import ThicknessDataset, ToTensor\n",
    "from src.models import U_Net\n",
    "from src.resnet import ResNet\n",
    "from src.trainer import Trainer\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "PATH = \"data\\gen_data_6000_v2\"\n",
    "\n",
    "augs = A.Compose([A.Normalize(mean = (0, 0, 0),\n",
    "                              std  = (1, 1, 1)),\n",
    "                 ToTensorV2()])\n",
    "thickness_dataset = ThicknessDataset(PATH, transform=augs)\n",
    "\n",
    "# https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/03/08/image-mean-std.html Could be worth attempting to normalise the data\n",
    "# https://stackoverflow.com/questions/41428868/image-preprocessing-in-deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3000\n",
    "sample = thickness_dataset[idx]\n",
    "\n",
    "print(\"cam_pos: \", sample['cam_pos'])\n",
    "print(\"catagory: \", sample['catagory'])\n",
    "print(\"model_id: \", sample['model_id'])\n",
    "print(\"sample_no: \", sample['sample_no'])\n",
    "\n",
    "img = sample['img']\n",
    "vis = sample['depth_map'].reshape(128,128)\n",
    "vis = vis[np.nonzero(vis)]\n",
    "\n",
    "print(img.shape)\n",
    "img = img.numpy().transpose(1, 2, 0)\n",
    "\n",
    "# Displays ehhe\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot()\n",
    "ax.imshow(img)\n",
    "\n",
    "plt.title(f\"{sample['catagory']}, {sample['model_id']}, {sample['sample_no']}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and std\n",
    "image_loader = DataLoader(thickness_dataset, \n",
    "                          batch_size  = 128, \n",
    "                          shuffle     = False, \n",
    "                          num_workers = 4,\n",
    "                          pin_memory  = True)\n",
    "\n",
    "# placeholders\n",
    "psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "# loop through images\n",
    "for inputs in tqdm(image_loader):\n",
    "    psum    += inputs['img'].sum(axis        = [0, 2, 3])\n",
    "    psum_sq += (inputs['img'] ** 2).sum(axis = [0, 2, 3])\n",
    "\n",
    "# pixel count\n",
    "count = len(thickness_dataset) * 128 * 128\n",
    "\n",
    "# mean and std\n",
    "total_mean = psum / count\n",
    "total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "total_std  = torch.sqrt(total_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = A.Compose([A.Normalize(mean = total_mean,\n",
    "                              std  = total_std),\n",
    "                 ToTensorV2()])\n",
    "thickness_dataset_without_big = ThicknessDataset(PATH, mode=1, transform=augs)\n",
    "thickness_dataset_only_big = ThicknessDataset(PATH, mode=2, transform=augs)\n",
    "print(\"Number of samples in dataset without large object\", len(thickness_dataset_without_big))\n",
    "print(\"Number of samples in dataset with only large objects\", len(thickness_dataset_only_big))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.9\n",
    "valid_split = 0.1\n",
    "train_size = int(train_split * len(thickness_dataset_without_big))+1\n",
    "valid_size = int(valid_split * len(thickness_dataset_without_big))\n",
    "\n",
    "\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(thickness_dataset_without_big, [train_size, valid_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "test_dataset = thickness_dataset_only_big\n",
    "\n",
    "batch_size = 16 # 16\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class berHuLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(berHuLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target, delta=1.0):\n",
    "        assert pred.dim() == target.dim(), \"inconsistent dimensions\"\n",
    "\n",
    "        error = target - pred\n",
    "        abs_error = torch.abs(error)\n",
    "        mask = abs_error < delta\n",
    "        squared_loss = 0.5 * torch.square(error)\n",
    "        linear_loss = delta * (abs_error - 0.5 * delta)\n",
    "        loss = torch.where(mask, squared_loss, linear_loss)\n",
    "        return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNet()\n",
    "\n",
    "model = U_Net()\n",
    "\n",
    "epochs = 200\n",
    "learning_rate = 2e-4\n",
    "scheduler = None\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, verbose=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0005)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "trainer = Trainer(model, optimizer, loss_fn, train_dataloader, valid_dataloader, scheduler=scheduler)\n",
    "trained_model = trainer.run(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "trained_model=model\n",
    "trained_model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = iter(train_dataloader).next()\n",
    "    image, label = data['img'].to(device, dtype=torch.float), data['thick_map'].to(device, dtype=torch.float)\n",
    "    output = trained_model(image)\n",
    "    image = image.cpu().numpy().transpose(0,2,3,1)\n",
    "    label = label.cpu().numpy()\n",
    "    output = output.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(image[0], cmap='gray')\n",
    "    plt.title('Input Image')\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(label[0].reshape(128,128), cmap='gray')\n",
    "    plt.title('Ground Truth')\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(output[0].reshape(128,128), cmap='gray')\n",
    "    plt.title('Predicted Thickness Map')\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(abs(label[0]-output[0]).reshape(128,128), cmap='gray')\n",
    "    plt.title('Diff')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "270a635b83e65d335eba5d097089b0ff08369f0634f543893019998ee28e2990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
